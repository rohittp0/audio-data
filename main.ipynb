{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YNySlTL2jibY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k8LOOjSvjobK"
   },
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = ['spoof', 'bonafide']\n",
    "map_class_to_id = {'spoof':0, 'bonafide':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qalD65OxjyRO"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "4S-WI5gKyWDn",
    "outputId": "f6ceb570-e91d-4eed-f199-f759193779b3"
   },
   "outputs": [],
   "source": [
    "def read_csv(path, base_data_path):\n",
    "    pd_data = pd.read_csv(path)\n",
    "\n",
    "    filtered_pd = pd_data[pd_data.category.isin(label_classes)]\n",
    "\n",
    "    class_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\n",
    "    filtered_pd = filtered_pd.assign(target=class_id)\n",
    "\n",
    "    full_path = filtered_pd['filename'].apply(lambda row: os.path.join(base_data_path, row))\n",
    "    filtered_pd = filtered_pd.assign(filename=full_path)\n",
    "\n",
    "    filenames = filtered_pd['filename']\n",
    "    targets = filtered_pd['target']\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((filenames, targets)), len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_for_map(filename, label):\n",
    "    return load_wav_16k_mono(filename), label, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(wav_data, label, fold):\n",
    "    scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(fold, num_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SG6FtmdwymZb",
    "outputId": "8c31b784-1fb4-48fa-ec87-0ee781a68ef2"
   },
   "outputs": [],
   "source": [
    "def load_ds(csv, folder):\n",
    "    ds, ds_len = read_csv(csv, folder)\n",
    "    ds = ds.map(load_wav_for_map)\n",
    "    ds = ds.map(extract_embedding).unbatch()\n",
    "    return ds.map(lambda embedding, label, fold: (embedding, label)).cache(), ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rr0203PR1GJ-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function resample at 0x0000023C3A4EE560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n",
      "caused by: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function resample at 0x0000023C3A4EE560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n",
      "caused by: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function resample at 0x0000023C3A4EE560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n",
      "caused by: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\tproh\\AppData\\Local\\Temp\\ipykernel_18368\\141038387.py\", line 2, in load_wav_for_map  *\n        return load_wav_16k_mono(filename), label, 1\n    File \"C:\\Users\\tproh\\AppData\\Local\\Temp\\ipykernel_18368\\590973627.py\", line 10, in load_wav_16k_mono  *\n        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 462, in resample  **\n        value = tf.vectorized_map(f, input)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m cached_ds, ds_length \u001B[38;5;241m=\u001B[39m \u001B[43mload_ds\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(ds_length \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.8\u001B[39m)\n\u001B[0;32m      4\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m cached_ds\u001B[38;5;241m.\u001B[39mtake(train_size)\n",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m, in \u001B[0;36mload_ds\u001B[1;34m(csv, folder)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_ds\u001B[39m(csv, folder):\n\u001B[0;32m      2\u001B[0m     ds, ds_len \u001B[38;5;241m=\u001B[39m read_csv(csv, folder)\n\u001B[1;32m----> 3\u001B[0m     ds \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mload_wav_for_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     ds \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mmap(extract_embedding)\u001B[38;5;241m.\u001B[39munbatch()\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ds\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m embedding, label, fold: (embedding, label))\u001B[38;5;241m.\u001B[39mcache(), ds_len\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[0;32m   2199\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m DEBUG_MODE:\n\u001B[0;32m   2200\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `deterministic` argument has no effect unless the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2201\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`num_parallel_calls` argument is specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2202\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2203\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2204\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m ParallelMapDataset(\n\u001B[0;32m   2205\u001B[0m       \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   2206\u001B[0m       map_func,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2209\u001B[0m       preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   2210\u001B[0m       name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001B[0m, in \u001B[0;36mMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[0;32m   5398\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[0;32m   5399\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality \u001B[38;5;241m=\u001B[39m preserve_cardinality\n\u001B[1;32m-> 5400\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5402\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5404\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5405\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n\u001B[0;32m   5406\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mmap_dataset(\n\u001B[0;32m   5407\u001B[0m     input_dataset\u001B[38;5;241m.\u001B[39m_variant_tensor,  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   5408\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5411\u001B[0m     preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality,\n\u001B[0;32m   5412\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_common_args)\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m    264\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    265\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    266\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    267\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    268\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    269\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[1;32m--> 271\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[0;32m    273\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2601\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   2602\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[0;32m   2603\u001B[0m \n\u001B[0;32m   2604\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2608\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[0;32m   2609\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2610\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_concrete_function_garbage_collected(\n\u001B[0;32m   2611\u001B[0m       \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2612\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   2613\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2574\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   2575\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m-> 2576\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2577\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m   2578\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[0;32m   2579\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   2758\u001B[0m   \u001B[38;5;66;03m# Only get placeholders for arguments, not captures\u001B[39;00m\n\u001B[0;32m   2759\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m placeholder_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m-> 2760\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2762\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39m_capture_func_lib  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   2763\u001B[0m \u001B[38;5;66;03m# Maintain the list of all captures\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   2665\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   2666\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[0;32m   2667\u001B[0m ]\n\u001B[0;32m   2668\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[0;32m   2669\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[1;32m-> 2670\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2671\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2672\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2673\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2675\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2678\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2679\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   2680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[0;32m   2681\u001B[0m     spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[0;32m   2682\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[0;32m   2683\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[0;32m   2684\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[0;32m   2685\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[0;32m   2686\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   2687\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001B[0m\n\u001B[0;32m   1244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1245\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[1;32m-> 1247\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m python_func(\u001B[38;5;241m*\u001B[39mfunc_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfunc_kwargs)\n\u001B[0;32m   1249\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[0;32m   1250\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[0;32m   1251\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[0;32m   1252\u001B[0m     convert, func_outputs, expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;129m@eager_function\u001B[39m\u001B[38;5;241m.\u001B[39mdefun_with_attributes(\n\u001B[0;32m    243\u001B[0m     input_signature\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_specs(\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_structure),\n\u001B[0;32m    245\u001B[0m     autograph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    246\u001B[0m     attributes\u001B[38;5;241m=\u001B[39mdefun_kwargs)\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[1;32m--> 248\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    249\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[0;32m    176\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[1;32m--> 177\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n\u001B[0;32m    179\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(ret)\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    691\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 692\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m    693\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    694\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    691\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    438\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 439\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    440\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    441\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filed7b_nrh5.py:12\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__load_wav_for_map\u001B[1;34m(filename, label)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     11\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m (\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mload_wav_16k_mono\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m, ag__\u001B[38;5;241m.\u001B[39mld(label), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[1;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    458\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef9d4tqjp.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__load_wav_16k_mono\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m     13\u001B[0m wav \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39msqueeze, (ag__\u001B[38;5;241m.\u001B[39mld(wav),), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope)\n\u001B[0;32m     14\u001B[0m sample_rate \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mcast, (ag__\u001B[38;5;241m.\u001B[39mld(sample_rate),), \u001B[38;5;28mdict\u001B[39m(dtype\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mint64), fscope)\n\u001B[1;32m---> 15\u001B[0m wav \u001B[38;5;241m=\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtfio\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrate_in\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrate_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16000\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:462\u001B[0m, in \u001B[0;36mresample\u001B[1;34m(input, rate_in, rate_out, name)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(i):\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m core_ops\u001B[38;5;241m.\u001B[39mio_audio_resample(\n\u001B[0;32m    459\u001B[0m         i, rate_in\u001B[38;5;241m=\u001B[39mrate_in, rate_out\u001B[38;5;241m=\u001B[39mrate_out, name\u001B[38;5;241m=\u001B[39mname\n\u001B[0;32m    460\u001B[0m     )\n\u001B[1;32m--> 462\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectorized_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mg1\u001B[39m():\n\u001B[0;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39msqueeze(value, [\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:458\u001B[0m, in \u001B[0;36mresample.<locals>.f\u001B[1;34m(i)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(i):\n\u001B[1;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcore_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio_audio_resample\u001B[49m(\n\u001B[0;32m    459\u001B[0m         i, rate_in\u001B[38;5;241m=\u001B[39mrate_in, rate_out\u001B[38;5;241m=\u001B[39mrate_out, name\u001B[38;5;241m=\u001B[39mname\n\u001B[0;32m    460\u001B[0m     )\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:88\u001B[0m, in \u001B[0;36mLazyLoader.__getattr__\u001B[1;34m(self, attrb)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, attrb):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, attrb)\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:84\u001B[0m, in \u001B[0;36mLazyLoader._load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mod \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mod \u001B[38;5;241m=\u001B[39m \u001B[43m_load_library\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_library\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mod\n",
      "File \u001B[1;32m~\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:69\u001B[0m, in \u001B[0;36m_load_library\u001B[1;34m(filename, lib)\u001B[0m\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (tf\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mNotFoundError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     68\u001B[0m         errs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mstr\u001B[39m(e))\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munable to open file: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, from paths: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilenames\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mcaused by: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merrs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     72\u001B[0m )\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: in user code:\n\n    File \"C:\\Users\\tproh\\AppData\\Local\\Temp\\ipykernel_18368\\141038387.py\", line 2, in load_wav_for_map  *\n        return load_wav_16k_mono(filename), label, 1\n    File \"C:\\Users\\tproh\\AppData\\Local\\Temp\\ipykernel_18368\\590973627.py\", line 10, in load_wav_16k_mono  *\n        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 462, in resample  **\n        value = tf.vectorized_map(f, input)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"C:\\Users\\tproh\\Downloads\\fake-audio\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['C:\\\\Users\\\\tproh\\\\Downloads\\\\fake-audio\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n"
     ]
    }
   ],
   "source": [
    "cached_ds, ds_length = load_ds('train.csv', 'train')\n",
    "train_size = int(ds_length * 0.8)\n",
    "\n",
    "train_ds = cached_ds.take(train_size)\n",
    "val_ds = cached_ds.skip(train_size)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds, _ = load_ds('test.csv', 'test')\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bI_rZY7P1NlM",
    "outputId": "11e41a3f-12d9-4932-b88b-ed57895d332a"
   },
   "outputs": [],
   "source": [
    "feature_classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=1024, dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(label_classes))\n",
    "], name='feature_classifier')\n",
    "\n",
    "feature_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8lNznnM1QB8"
   },
   "outputs": [],
   "source": [
    "feature_classifier.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y %m %d-%H %M %S\")\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks = [early_stopping_callback, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQe4CH7O1Sh-",
    "outputId": "c75834e1-f4c8-4185-e70b-cc4861f6f3ed"
   },
   "outputs": [],
   "source": [
    "history = feature_classifier.fit(train_ds,\n",
    "                       epochs=50,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7aR7mesFpvX"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = feature_classifier.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJMl1ahWGYph"
   },
   "outputs": [],
   "source": [
    "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, axis=0, **kwargs):\n",
    "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
    "    self.axis = axis\n",
    "\n",
    "  def call(self, inp):\n",
    "    return tf.math.reduce_mean(inp, axis=self.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KCMQsUA7GZdY",
    "outputId": "1d694175-b380-428d-8f81-af1af5f3a47a"
   },
   "outputs": [],
   "source": [
    "saved_model_path = 'model'\n",
    "\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
    "                                            trainable=False, name='yamnet')\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
    "serving_outputs = feature_classifier(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "serving_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "f71sybKEGiCD",
    "outputId": "c62e4f48-2c81-4235-bf16-730f76f111cd"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(serving_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVIVBp5NGnIt"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Ethinte thaze run cheytha model use cheyya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmWs5Q2zGkq3"
   },
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "UNCsjnN6HfDx",
    "outputId": "47e2ff74-ea3c-4e5d-ea3c-31e18cd23ef4"
   },
   "outputs": [],
   "source": [
    "testing_wav_data = # Load some data to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwwPDHmmHTEA"
   },
   "outputs": [],
   "source": [
    "serving_results = reloaded_model.signatures['serving_default'](testing_wav_data)\n",
    "real_or_fake = label_classes[tf.math.argmax(serving_results['classifier'])]\n",
    "print(f'The input sound is: {real_or_fake}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
